[AI让效率再次提升，人类该干什么？](https://tumutanzi.com/archives/17493)

## LLM

[最好的致敬是学习：DeepSeek-R1 赏析](https://mp.weixin.qq.com/s/_XGBipbywCOtcKu13QDW5Q)

## 入门
[CPU vs. GPU](https://www.infoq.cn/article/UU1l5ayRqQBNyKZtLFQo?utm_source=rss&utm_medium=article)

[机器学习知识体系](https://www.zhihu.com/question/266291909/answer/2543083234)

[沈向洋：浅谈人工智能创造](https://event.baai.ac.cn/play/89)  [.pdf](data/static_pages/pdf/1.pdf) 

## 理解

[TensorFlow 篇 | TensorFlow 2.x 模型 Serving 服务](https://flashgene.com/archives/154963.html)

[Keras Optimizers](https://keras.io/zh/optimizers/#adagrad)

[Keras activations](https://keras.io/zh/activations/#sigmoid)

[SHAP：Python的可解释机器学习库](https://zhuanlan.zhihu.com/p/83412330)

[可解释性机器学习_Feature Importance、Permutation Importance、SHAP](https://blog.csdn.net/weixin_44803791/article/details/109776357)

[深入学习卷积神经网络中卷积层和池化层的意义](https://www.cnblogs.com/wj-1314/p/9593364.html)

[一文搞懂RNN（循环神经网络）基础篇](https://zhuanlan.zhihu.com/p/30844905)
>循环神经网络的隐藏层的值s不仅仅取决于当前这次的输入x，还取决于上一次隐藏层的值s。权重矩阵 W就是隐藏层上一次的值作为这一次的输入的权重。

[过拟合](https://juejin.cn/post/7087483936237944839)
>Dropout 可以认为是一种模型训练方法，其中每批数据训练时只有一定比例的权重被更新，而其余的权重不被更新

## 应用
[Interactive Video Stylization Using Few-Shot Patch-Based Training](https://github.com/OndrejTexler/Few-Shot-Patch-Based-Training)

[AI 作曲 （完整思路）](https://eurychen.me/post/music/ai-compose-music/)
>美不能被量化，但却有迹可循。AI 三脚猫功夫般的作曲，即是一种证明。
